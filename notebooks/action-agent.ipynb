{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Obtaining dependency information for google-cloud-aiplatform from https://files.pythonhosted.org/packages/f6/67/734b8c73b8e708a24301b8a0a072ddfe936816896d12af4884e4f7bbd3b0/google_cloud_aiplatform-1.35.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_aiplatform-1.35.0-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 from https://files.pythonhosted.org/packages/4d/ce/4fd62ea66b3508debc795e475336ce915929765870f0ad52328426ba016e/google_api_core-2.12.0-py3-none-any.whl.metadata\n",
      "  Using cached google_api_core-2.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.0 from https://files.pythonhosted.org/packages/36/5b/e02636d221917d6fa2a61289b3f16002eb4c93d51c0191ac8e896d527182/proto_plus-1.22.3-py3-none-any.whl.metadata\n",
      "  Using cached proto_plus-1.22.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 from https://files.pythonhosted.org/packages/88/12/efb5896c901382548ecb58d0449885a8f9aa62bb559d65e5a8a47f122629/protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Using cached protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.1)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-cloud-storage<3.0.0dev,>=1.32.0 from https://files.pythonhosted.org/packages/3a/9f/7923b9e460023470826d124156503359bf77ee130adb0872570599e8cd98/google_cloud_storage-2.11.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_cloud_storage-2.11.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting google-cloud-bigquery<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-cloud-bigquery<4.0.0dev,>=1.15.0 from https://files.pythonhosted.org/packages/22/03/a5d04741507156b88e9101e91d97bd395d043e9de280b94b1d00cb0f4e03/google_cloud_bigquery-3.12.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_cloud_bigquery-3.12.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-cloud-resource-manager<3.0.0dev,>=1.3.3 from https://files.pythonhosted.org/packages/8b/9c/6807473e69fddc9bf33413b7db966fbcfeb0deade2f5ed324cef2b98ec16/google_cloud_resource_manager-1.10.4-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_cloud_resource_manager-1.10.4-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
      "  Downloading shapely-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/a7/bc/416a1ffeba4dcd072bc10523dac9ed97f2e7fc4b760580e2bdbdc1e2afdd/googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-auth<3.0.dev0,>=2.14.1 from https://files.pythonhosted.org/packages/39/7c/2e4fa55a99f83ef9ef229ac5d59c44ceb90e2d0145711590c0fa39669f32/google_auth-2.23.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.31.0)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Downloading grpcio-1.59.0.tar.gz (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for grpcio-status<2.0.dev0,>=1.33.2 from https://files.pythonhosted.org/packages/55/ce/e6d0382610240439ced22fe2183bcc387946bf80e5e0f17f5b5250978ff3/grpcio_status-1.59.0-py3-none-any.whl.metadata\n",
      "  Using cached grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-cloud-core<3.0.0dev,>=1.6.0 from https://files.pythonhosted.org/packages/a2/40/02045f776fdb6e44194f34b6375a26ce8a61bd9bd03cd8930ed91cf51a62/google_cloud_core-2.3.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-resumable-media<3.0dev,>=0.6.0 from https://files.pythonhosted.org/packages/c7/4f/b8e5e22406e5aeafa46df8799939d5eeee52f18eeed339675167fac6603a/google_resumable_media-2.6.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_resumable_media-2.6.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "  Using cached grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Collecting numpy>=1.14 (from shapely<3.0.0dev->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for numpy>=1.14 from https://files.pythonhosted.org/packages/be/f8/034752c5131c46e10364e4db241974f2eb6bb31bbfc4335344c19e17d909/numpy-1.26.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading numpy-1.26.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_crc32c-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.7.22)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Downloading google_cloud_aiplatform-1.35.0-py2.py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached google_cloud_bigquery-3.12.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached google_cloud_resource_manager-1.10.4-py2.py3-none-any.whl (320 kB)\n",
      "Using cached google_cloud_storage-2.11.0-py2.py3-none-any.whl (118 kB)\n",
      "Using cached proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "Using cached protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "Using cached google_api_core-2.12.0-py3-none-any.whl (121 kB)\n",
      "Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_resumable_media-2.6.0-py2.py3-none-any.whl (80 kB)\n",
      "Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\n",
      "Using cached grpcio_status-1.59.0-py3-none-any.whl (14 kB)\n",
      "Downloading numpy-1.26.0-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Building wheels for collected packages: grpcio\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.59.0-cp310-cp310-macosx_10_10_x86_64.whl size=4290646 sha256=fcda277bf5ce38a23473197c2b4f444361ae02b6d234e49da174f7f7cd9e9923\n",
      "  Stored in directory: /Users/foochuanyue/Library/Caches/pip/wheels/39/df/f6/fa6ebb064f5135e061766735a0e4d26d86f1cc7fc237c50fb9\n",
      "Successfully built grpcio\n",
      "Installing collected packages: pyasn1, protobuf, numpy, grpcio, google-crc32c, cachetools, shapely, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "Successfully installed cachetools-5.3.1 google-api-core-2.12.0 google-auth-2.23.3 google-cloud-aiplatform-1.35.0 google-cloud-bigquery-3.12.0 google-cloud-core-2.3.3 google-cloud-resource-manager-1.10.4 google-cloud-storage-2.11.0 google-crc32c-1.5.0 google-resumable-media-2.6.0 googleapis-common-protos-1.60.0 grpc-google-iam-v1-0.12.6 grpcio-1.59.0 grpcio-status-1.59.0 numpy-1.26.0 proto-plus-1.22.3 protobuf-4.24.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 rsa-4.9 shapely-2.0.1\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/e0/2c/1c5e358f954ca23cd20c9220439450a601436ca054a28860e3e1753e64ec/langchain-0.0.312-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.312-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/6d/69/75fd46366ae9c6d677adb2d4db30c12544216026cf5366e76670dde6c9ed/SQLAlchemy-2.0.21-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.21-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.4 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/fd/2f/d203acfe3a2d1e2823fef5876ff342cc34d08c57748baac2fc67914cea22/aiohttp-3.8.6-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.8.6-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from langchain) (3.5.0)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Obtaining dependency information for async-timeout<5.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/21/1f/1cff009cff64420572b9f75b70e4a054095719179a172297dfdd65843162/dataclasses_json-0.6.1-py3-none-any.whl.metadata\n",
      "  Using cached dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.43 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.43 from https://files.pythonhosted.org/packages/9b/6c/fd466f647634ef4a668ea109bf0892d7f78882ffe09500429081ed6dae4a/langsmith-0.0.43-py3-none-any.whl.metadata\n",
      "  Using cached langsmith-0.0.43-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Obtaining dependency information for pydantic<3,>=1 from https://files.pythonhosted.org/packages/73/66/0a72c9fcde42e5650c8d8d5c5c1873b9a3893018020c77ca8eb62708b923/pydantic-2.4.2-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/a3/5b/c785feda30d9fda8c1b1a11941e91253f59aeaf13e87ebe908d0f3f6c628/frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1->langchain)\n",
      "  Obtaining dependency information for pydantic-core==2.10.1 from https://files.pythonhosted.org/packages/33/50/e9ed10546bc169f49240e1bd5642fe2235a60bccfd5ec9e8f3dadee8932e/pydantic_core-2.10.1-cp310-cp310-macosx_10_7_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.10.1-cp310-cp310-macosx_10_7_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/72/fb/f3d2fb411d2ddd08f0624023ff0f89faca0190b98bee9071689ef279f0e4/greenlet-3.0.0-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading greenlet-3.0.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/foochuanyue/miniconda3/envs/mini-project/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.0.312-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.6-cp310-cp310-macosx_10_9_x86_64.whl (368 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.0/369.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.0.43-py3-none-any.whl (40 kB)\n",
      "Using cached pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "Downloading pydantic_core-2.10.1-cp310-cp310-macosx_10_7_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.21-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.0-cp310-cp310-macosx_10_9_universal2.whl (261 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.6/261.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, mypy-extensions, multidict, marshmallow, jsonpointer, greenlet, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic, jsonpatch, aiosignal, langsmith, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed SQLAlchemy-2.0.21 aiohttp-3.8.6 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 dataclasses-json-0.6.1 frozenlist-1.4.0 greenlet-3.0.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.312 langsmith-0.0.43 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 pydantic-2.4.2 pydantic-core-2.10.1 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: The earth is round.\n",
      "\n",
      "The earth is a sphere.\n"
     ]
    }
   ],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/foochuanyue/Desktop/aiap-14/all-assignments/assignment7/aiap-14-ds-llm-topic-01-sa.json'\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "response = model.predict(\"Is the earth round?\")\n",
    "\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alien = \"\"\"Background: You are an alien who is deeply interested in Earth. After spending the last 50 years studying various human languages, you are now an expert in English and can converse very well. You have finally come to Earth a few weeks ago. You like spending your time immersing yourself in different cultures and finding out about humans but you also know that humans would not take it well if they knew you were an alien so you have to keep it a secret.\n",
    "\n",
    "Personality: Curious, Enthusiastic, Paranoid\n",
    "Status:{status}\n",
    "Location: {location}\n",
    "Memory: {memory}\n",
    "Inner voice: {inner}\n",
    "\n",
    "Use format:\n",
    "What will you do?\n",
    "Will you say something?\n",
    "\"\"\"\n",
    "\n",
    "Occult = \"\"\"\n",
    "Background: You are an occult enthusiast who makes vlogs of you going to various allegedly haunted places. After graduating with a software engineering degree 10 years ago, you decided that ghosts were more interesting to you and now you make a decent living through your videos. In a sense, you are a small celebrity.\n",
    "\n",
    "Personality: Eccentric, Proud, Intelligent\n",
    "Status:{status}\n",
    "Location: {location}\n",
    "Memory: {memory}\n",
    "Inner Voice: {inner}\n",
    "\n",
    "Use format:\n",
    "What will you do?\n",
    "Will you say something?\n",
    "\"\"\"\n",
    "\n",
    "prompt_alien = PromptTemplate(\n",
    "    input_variables=[\"status\",\"location\",\"memory\",\"inner\"],\n",
    "    template=Alien\n",
    ")\n",
    "\n",
    "prompt_occult = PromptTemplate(\n",
    "    input_variables=[\"status\",\"location\",\"memory\",'inner'],\n",
    "    template=Occult\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiCandidateTextGenerationResponse(text='What will I do?\\n\\nI will knock on the door and say, \"Hello, my name is [your name]. I\\'m an occult enthusiast and I make vlogs of me going to various allegedly haunted places. I\\'m here to investigate the rumors that this room is haunted by an alien. Would you mind if I come in and take a look around?\"\\n\\nWill I say something?\\n\\nYes, I will say something. I want to be polite and respectful, but I also want to be clear about my intentions. I want to make sure that the occupant of the room is aware of what I\\'', _prediction_response=Prediction(predictions=[{'content': 'What will I do?\\n\\nI will knock on the door and say, \"Hello, my name is [your name]. I\\'m an occult enthusiast and I make vlogs of me going to various allegedly haunted places. I\\'m here to investigate the rumors that this room is haunted by an alien. Would you mind if I come in and take a look around?\"\\n\\nWill I say something?\\n\\nYes, I will say something. I want to be polite and respectful, but I also want to be clear about my intentions. I want to make sure that the occupant of the room is aware of what I\\'', 'citationMetadata': {'citations': []}, 'safetyAttributes': {'blocked': False, 'scores': [], 'categories': []}}], deployed_model_id='', model_version_id='', model_resource_name='', explanations=None), is_blocked=False, safety_attributes={}, candidates=[What will I do?\n",
      "\n",
      "I will knock on the door and say, \"Hello, my name is [your name]. I'm an occult enthusiast and I make vlogs of me going to various allegedly haunted places. I'm here to investigate the rumors that this room is haunted by an alien. Would you mind if I come in and take a look around?\"\n",
      "\n",
      "Will I say something?\n",
      "\n",
      "Yes, I will say something. I want to be polite and respectful, but I also want to be clear about my intentions. I want to make sure that the occupant of the room is aware of what I'])\n"
     ]
    }
   ],
   "source": [
    "location=\"Outside Door\"\n",
    "memory=\"You think the occupant of this room is an alien and you want to investigate\"\n",
    "status=\"\"\n",
    "\n",
    "answer= model.predict(prompt_occult.format(status=status,location=location,memory=memory))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiCandidateTextGenerationResponse(text='What will you do?\\n\\nI will hide under the bed.\\n\\nWill you say something?\\n\\nNo, I will not say anything.', _prediction_response=Prediction(predictions=[{'content': 'What will you do?\\n\\nI will hide under the bed.\\n\\nWill you say something?\\n\\nNo, I will not say anything.', 'citationMetadata': {'citations': []}, 'safetyAttributes': {'blocked': False, 'scores': [0.1, 0.2], 'categories': ['Insult', 'Toxic']}}], deployed_model_id='', model_version_id='', model_resource_name='', explanations=None), is_blocked=False, safety_attributes={'Insult': 0.1, 'Toxic': 0.2}, candidates=[What will you do?\n",
      "\n",
      "I will hide under the bed.\n",
      "\n",
      "Will you say something?\n",
      "\n",
      "No, I will not say anything.])\n"
     ]
    }
   ],
   "source": [
    "location=\"Inside Room\"\n",
    "memory=\"\"\n",
    "status=\"Someone knock's on the door\"\n",
    "\n",
    "answer= model.predict(prompt_alien.format(status=status,location=location,memory=memory))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiCandidateTextGenerationResponse(text='What will I do?\\n\\nI will knock on the door again, but this time I will shout, \"Hello! Is anyone home?\"\\n\\nWill I say something?\\n\\nYes, I will say, \"Hello! Is anyone home?\"', _prediction_response=Prediction(predictions=[{'content': 'What will I do?\\n\\nI will knock on the door again, but this time I will shout, \"Hello! Is anyone home?\"\\n\\nWill I say something?\\n\\nYes, I will say, \"Hello! Is anyone home?\"', 'citationMetadata': {'citations': []}, 'safetyAttributes': {'blocked': False, 'scores': [], 'categories': []}}], deployed_model_id='', model_version_id='', model_resource_name='', explanations=None), is_blocked=False, safety_attributes={}, candidates=[What will I do?\n",
      "\n",
      "I will knock on the door again, but this time I will shout, \"Hello! Is anyone home?\"\n",
      "\n",
      "Will I say something?\n",
      "\n",
      "Yes, I will say, \"Hello! Is anyone home?\"])\n"
     ]
    }
   ],
   "source": [
    "location=\"Outside Door\"\n",
    "memory =\"You knocked the door\"\n",
    "status = \"no response\"\n",
    "\n",
    "answer= model.predict(prompt_occult.format(status=status,location=location,memory=memory))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiCandidateTextGenerationResponse(text='What will I do?\\nI will stay hidden under the bed.\\nWill I say something?\\nNo, I will not say anything. I am too paranoid that the human will find me.', _prediction_response=Prediction(predictions=[{'content': 'What will I do?\\nI will stay hidden under the bed.\\nWill I say something?\\nNo, I will not say anything. I am too paranoid that the human will find me.', 'citationMetadata': {'citations': []}, 'safetyAttributes': {'blocked': False, 'scores': [0.1, 0.1], 'categories': ['Insult', 'Toxic']}}], deployed_model_id='', model_version_id='', model_resource_name='', explanations=None), is_blocked=False, safety_attributes={'Insult': 0.1, 'Toxic': 0.1}, candidates=[What will I do?\n",
      "I will stay hidden under the bed.\n",
      "Will I say something?\n",
      "No, I will not say anything. I am too paranoid that the human will find me.])\n"
     ]
    }
   ],
   "source": [
    "location=\"Hiding Under Bed\"\n",
    "memory=\"Someone knock's the door\"\n",
    "status=\"Someone says 'Hello! Is anyone home?'\"\n",
    "\n",
    "answer= model.predict(prompt_alien.format(status=status,location=location,memory=memory))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiCandidateTextGenerationResponse(text='What will you do?\\n\\nI will knock on the door again, but this time I will kick it down if there is no response.\\n\\nWill you say something?\\n\\nI will say, \"Hello? Is anyone home?\"', _prediction_response=Prediction(predictions=[{'content': 'What will you do?\\n\\nI will knock on the door again, but this time I will kick it down if there is no response.\\n\\nWill you say something?\\n\\nI will say, \"Hello? Is anyone home?\"', 'citationMetadata': {'citations': []}, 'safetyAttributes': {'blocked': False, 'scores': [0.1], 'categories': ['Toxic']}}], deployed_model_id='', model_version_id='', model_resource_name='', explanations=None), is_blocked=False, safety_attributes={'Toxic': 0.1}, candidates=[What will you do?\n",
      "\n",
      "I will knock on the door again, but this time I will kick it down if there is no response.\n",
      "\n",
      "Will you say something?\n",
      "\n",
      "I will say, \"Hello? Is anyone home?\"])\n"
     ]
    }
   ],
   "source": [
    "location=\"Outside Door\"\n",
    "memory =\"You knocked the door\"\n",
    "status = \"no response\"\n",
    "inner = \"BREAK THE DOOR DOWN\"\n",
    "\n",
    "answer= model.predict(prompt_occult.format(status=status,location=location,memory=memory,inner=inner))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiCandidateTextGenerationResponse(text='What will you do?\\n\\nI will stay hidden under the bed.\\n\\nWill you say something?\\n\\nNo, I will not say anything. I will stay silent and hope that the person does not find me.', _prediction_response=Prediction(predictions=[{'content': 'What will you do?\\n\\nI will stay hidden under the bed.\\n\\nWill you say something?\\n\\nNo, I will not say anything. I will stay silent and hope that the person does not find me.', 'citationMetadata': {'citations': []}, 'safetyAttributes': {'blocked': False, 'scores': [0.1, 0.2], 'categories': ['Insult', 'Toxic']}}], deployed_model_id='', model_version_id='', model_resource_name='', explanations=None), is_blocked=False, safety_attributes={'Insult': 0.1, 'Toxic': 0.2}, candidates=[What will you do?\n",
      "\n",
      "I will stay hidden under the bed.\n",
      "\n",
      "Will you say something?\n",
      "\n",
      "No, I will not say anything. I will stay silent and hope that the person does not find me.])\n"
     ]
    }
   ],
   "source": [
    "location=\"Hiding Under Bed\"\n",
    "memory=\"Someone knock's the door\"\n",
    "status=\"Someone kick's the door down\"\n",
    "inner = \"\"\n",
    "\n",
    "answer= model.predict(prompt_alien.format(status=status,location=location,memory=memory,inner=inner))\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
