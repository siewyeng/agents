{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "os.environ[\n",
    "    \"GOOGLE_APPLICATION_CREDENTIALS\"\n",
    "] = \"credentials/aiap-14-ds-llm-topic-01-sa.json\"\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-experimental in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (0.0.29)\n",
      "Requirement already satisfied: langchain>=0.0.308 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain-experimental) (0.0.313)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (0.0.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from langchain>=0.0.308->langchain-experimental) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.308->langchain-experimental) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.308->langchain-experimental) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain>=0.0.308->langchain-experimental) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.308->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: langchain-experimental in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (0.0.29)\n",
      "Requirement already satisfied: langchain>=0.0.308 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain-experimental) (0.0.313)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (0.0.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from langchain>=0.0.308->langchain-experimental) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from langchain>=0.0.308->langchain-experimental) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.308->langchain-experimental) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.308->langchain-experimental) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain>=0.0.308->langchain-experimental) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.308->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\lenovo\\anaconda3\\envs\\assignment7\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tik-token (from versions: none)\n",
      "ERROR: No matching distribution found for tik-token\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-experimental\n",
    "!pip install termcolor\n",
    "!pip install langchain-experimental\n",
    "!pip install tik-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import VertexAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from src.generative_agents.generative_agent import StemssGenerativeAgent\n",
    "from src.generative_agents.memory import StemssGenerativeAgentMemory\n",
    "from src.retrievers.time_weighted_retriever import ModTimeWeightedVectorStoreRetriever\n",
    "from src.vectorstores.chroma import EnhancedChroma\n",
    "\n",
    "\n",
    "def relevance_score_fn(score: float) -> float:\n",
    "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "    # This will differ depending on a few things:\n",
    "    # - the distance / similarity metric used by the VectorStore\n",
    "    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
    "    # This function converts the euclidean norm of normalized embeddings\n",
    "    # (0 is most similar, sqrt(2) most dissimilar)\n",
    "    # to a similarity function (0 to 1)\n",
    "    return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "\n",
    "def create_new_memory_retriever(decay_rate: float = 0.5, k: int = 5):\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Define your embedding model\n",
    "    embeddings_model = VertexAIEmbeddings()\n",
    "    vs = EnhancedChroma(embedding_function=embeddings_model)\n",
    "    return ModTimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vs, other_score_keys=[\"importance\"], decay_rate=decay_rate, k=k\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "mem_file_joel = \"./memory/memory.csv\"\n",
    "mem_file_ellie = \"./memory/memory_ellie.csv\"\n",
    "\n",
    "\n",
    "def load_documents(mem_file):\n",
    "    \"\"\" \"Load memory (history) from CSV \"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of documents where each row of the CSV is a document\n",
    "    \"\"\"\n",
    "    loader = CSVLoader(\n",
    "        mem_file, metadata_columns=[\"last_accessed_at\", \"created_at\", \"importance\"]\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90aed9f1-69a9-11ee-b87d-106fd9de73c8',\n",
       " '90aed9f2-69a9-11ee-b912-106fd9de73c8',\n",
       " '90aed9f3-69a9-11ee-ba7b-106fd9de73c8',\n",
       " '90aed9f4-69a9-11ee-9499-106fd9de73c8',\n",
       " '90aed9f5-69a9-11ee-82aa-106fd9de73c8',\n",
       " '90aed9f6-69a9-11ee-9ac4-106fd9de73c8',\n",
       " '90aed9f7-69a9-11ee-94b0-106fd9de73c8',\n",
       " '90aed9f8-69a9-11ee-9ebd-106fd9de73c8',\n",
       " '90aed9f9-69a9-11ee-9b9d-106fd9de73c8',\n",
       " '90aed9fa-69a9-11ee-9d69-106fd9de73c8',\n",
       " '90aed9fb-69a9-11ee-8c32-106fd9de73c8']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = load_documents(mem_file=mem_file_joel)\n",
    "memory_retriever_joel = create_new_memory_retriever()\n",
    "memory_retriever_joel.add_documents(docs)\n",
    "\n",
    "docs = load_documents(mem_file=mem_file_ellie)\n",
    "memory_retriever_ellie = create_new_memory_retriever()\n",
    "memory_retriever_ellie.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "USER_NAME = \"Person A\"  # The name you want to use when interviewing the agent.\n",
    "llm = VertexAI(model_name=\"text-bison@001\", max_output_tokens=256, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generative_agents.generative_agent import StemssGenerativeAgent\n",
    "from src.generative_agents.memory import StemssGenerativeAgentMemory\n",
    "\n",
    "joel_memory = StemssGenerativeAgentMemory(\n",
    "    llm=llm,\n",
    "    memory_retriever=memory_retriever_joel,\n",
    "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "joel = StemssGenerativeAgent(\n",
    "    name=\"Joel\",\n",
    "    age=25,\n",
    "    traits=\"curious, enthusiastic, paranoid\",  # You can add more persistent traits here\n",
    "    status=\"going home for his birthday\",  # When connected to a virtual world, we can have the characters update their status\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    llm=llm,\n",
    "    memory=joel_memory,\n",
    "    background=\"Joel is a music lover with a knack for composing sad songs. Joel has posted many songs on YouTube and has gotten quite some views.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Joel (age: 25)\n",
      "Innate traits: curious, enthusiastic, paranoid\n",
      "Joel is a music lover who composes sad songs. He is also a good cook and enjoys watching movies.\n"
     ]
    }
   ],
   "source": [
    "print(joel.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellie_memory = StemssGenerativeAgentMemory(\n",
    "    llm=llm,\n",
    "    memory_retriever=memory_retriever_ellie,\n",
    "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "ellie = StemssGenerativeAgent(\n",
    "    name=\"Ellie\",\n",
    "    age=52,\n",
    "    traits=\"tired, hungry, well-read\",  # You can add more persistent traits here\n",
    "    status=\"finishing up retirement procedures\",  # When connected to a virtual world, we can have the characters update their status\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    llm=llm,\n",
    "    memory=ellie_memory,\n",
    "    background=\"Ellie has a 5 Phds and has been in Academia for 30 years. Ellie wants to travel the world and do voluntary work.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Ellie (age: 52)\n",
      "Innate traits: tired, hungry, well-read\n",
      "Ellie is a 50-year-old woman who has been in academia for 30 years. She has a Ph.D. in five different fields and is interested in traveling the world and doing voluntary work. She is married to Joel and they have a good relationship. Ellie is a kind and caring person who is always willing to help others. She is also very intelligent and creative.\n"
     ]
    }
   ],
   "source": [
    "print(ellie.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(\n",
    "    agents: List[StemssGenerativeAgent], initial_observation: str\n",
    ") -> None:\n",
    "    \"\"\"Runs a conversation between agents.\"\"\"\n",
    "    _, observation = agents[1].generate_reaction(initial_observation)\n",
    "    print(observation)\n",
    "    turns = 0\n",
    "    while True:\n",
    "        break_dialogue = False\n",
    "        for agent in agents:\n",
    "            # print(agent.generate_dialogue(, observation))\n",
    "            stay_in_dialogue, observation = agent.generate_dialogue(\n",
    "                agent.name, observation\n",
    "            )\n",
    "            # observation = f\"{agent.name} said {reaction}\"\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True\n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turns += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Joel said: Hi, Ellie. Thanks for agreeing to meet with me today. I have this paper that I have to complete tomorrow on the history of America. Could you teach me how to do it? and reacted by SAY: Of course, Joel. I'd be happy to help. Let's get started.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Ellie said Of course, Joel. I'd be happy to help. Let's get started.\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Joel observed Ellie said Of course, Joel. I'd be happy to help. Let's get started. and said Great! I'm really excited to learn more about the history of America.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Joel said Great! I'm really excited to learn more about the history of America. and said Great! Let's get started.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Joel observed Ellie said Great! Let's get started. and said Thanks Ellie! I'm really looking forward to learning more about the history of America.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Joel said Thanks Ellie! I'm really looking forward to learning more about the history of America. and said Of course, Joel. I'm happy to help. What do you want to know?\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Joel observed Ellie said Of course, Joel. I'm happy to help. What do you want to know? and said said I've always been interested in learning more about the history of America, but I've never had anyone to teach me.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Joel said said I've always been interested in learning more about the history of America, but I've never had anyone to teach me. and said I'm glad to hear that. I'm sure I can help you learn a lot about the history of America.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Joel observed Ellie said I'm glad to hear that. I'm sure I can help you learn a lot about the history of America. and said Great, I'm really looking forward to it.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Joel said Great, I'm really looking forward to it. and said Let's get started then.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Joel observed Ellie said Let's get started then. and said Great! I'm ready to learn.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Joel said Great! I'm ready to learn. and said Great! Let's start with the basics.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Joel observed Ellie said Great! Let's start with the basics. and said Great, I'm excited to learn!\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Joel said Great, I'm excited to learn! and said Great! Let's start with the basics.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "PROMPT: input_variables=['agent_name', 'agent_status', 'agent_summary_description', 'current_time', 'most_recent_memories', 'observation', 'relevant_memories'] template='{agent_summary_description}\\nIt is {current_time}.\\n{agent_name}\\'s status: {agent_status}\\nSummary of relevant context from {agent_name}\\'s memory:\\n{relevant_memories}\\nMost recent observations: {most_recent_memories}\\nObservation: {observation}\\n\\nWhat would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
      "======================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: Ellie observed Say: Great, I'm excited to learn! and said Great! Let's start with the basics.\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agents = [joel, ellie]\n",
    "run_conversation(\n",
    "    agents,\n",
    "    \"Joel said: Hi, Ellie. Thanks for agreeing to meet with me today. I have this paper that I have to complete tomorrow on the history of America. Could you teach me how to do it?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The entity in this observation is \"Joel\".\\n\\nThe observation is about Joel going to the park and seeing a chihuahua. The entity is the person who is doing the action. In this case, the person is Joel.\\n\\nThe relationship between Joel and The entity in this observation is \"Joel\" is that Joel is the person who is doing the action.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joel.summarize_speaker_memories(\"Joel is going to the park and sees a chihuahua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: ellie wakes up and hear's the alarm\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: ellie eats a boal of porridge\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: ellie helps a coworker on a task\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: ellie plays tennis with her friend Xu before going to work\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mOn the scale of 1 to 10, where 1 is not important at all (e.g., brushing teeth, making bed) and 10 is extremely important (e.g., a break up, college acceptance), rate the importance of the following piece of memory. You must respond with a single integer.\n",
      "Memory: ellie overhears her colleague say something about Tommie being hard to work with\n",
      "Rating: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ellie_observations = [\n",
    "    \"ellie wakes up and hear's the alarm\",\n",
    "    \"ellie eats a boal of porridge\",\n",
    "    \"ellie helps a coworker on a task\",\n",
    "    \"ellie plays tennis with her friend Xu before going to work\",\n",
    "    \"ellie overhears her colleague say something about Tommie being hard to work with\",\n",
    "]\n",
    "for observation in ellie_observations:\n",
    "    ellie.memory.add_memory(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
